MobileNNBench
=============

In recent years, the on device deep learning applications are getting more and
more popular. It's a challenging task for an app developer to deploy a
deep learning model in their applications. They need to choose proper
inference framework, optionally utilizing quantization or compression
techniques regarding to the precision-performance trade-off, and finally
deployed onto various heterogeneous compute devices.

The puropse of this project is to provide an end-to-end neural network benchmark
on mobile devices.
