MobileNNBench
=============
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![build status](http://v9.git.n.xiaomi.com/deep-computing/mobile-nn-bench/badges/master/build.svg)](http://v9.git.n.xiaomi.com/deep-computing/mobile-nn-bench/commits/master)

In recent years, the on device deep learning applications are getting more and
more popular. It's a challenging task for application developers to deploy their
deep learning models in their applications. They need to choose proper
inference framework, optionally utilizing quantization or compression
techniques regarding to the precision-performance trade-off, and finally
run the model on one or more of heterogeneous compute devices. How to make a
appropriate decision among these choices is a tedious and time consuming task.

The puropse of this project is to provide an end-to-end neural network benchmark
on mobile devices, which hopefully can provide insights for the developers.

## License
[Apache License 2.0](LICENSE).